{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0EnivMnImIykSVwfUyHKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai2475/Code_Alpha_Intern/blob/main/TASK2_chatbot_using_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "ISfhiiumjsUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "2K6O5iGUjWBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing NLTK\n"
      ],
      "metadata": {
        "id": "4VRPZ3Vnjyjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw-12norj2LZ",
        "outputId": "6694de8e-d753-4270-fbf7-514523915716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_corpus = [\n",
        "    \"Hello! How can I help you?\",\n",
        "    \"I am a chatbot built using NLTK.\",\n",
        "    \"You can ask me questions about AI, NLP, or anything else!\",\n",
        "    \"I can help with Python, machine learning, and deep learning.\",\n",
        "    \"Natural Language Processing is a field of AI that helps computers understand human language.\",\n",
        "    \"Groq is a fast inference engine for AI models.\",\n",
        "    \"Llama 3 is a powerful open-source LLM.\",\n",
        "    \"Vector databases like ChromaDB store embeddings for fast retrieval.\",\n",
        "    \"You can deploy AI chatbots using Flask or FastAPI.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "lsNyZK0DkGRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def preprocess(text):\n",
        "    return text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Store both original and preprocessed versions\n",
        "preprocessed_corpus = [preprocess(sent) for sent in chatbot_corpus]"
      ],
      "metadata": {
        "id": "ymc4zS7LlO9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(preprocessed_corpus)\n"
      ],
      "metadata": {
        "id": "B2xaFZhan-TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate chatbot responses\n",
        "def chatbot_response(user_input):\n",
        "    user_input = preprocess(user_input)\n",
        "    user_vector = vectorizer.transform([user_input])\n",
        "    similarity_scores = cosine_similarity(user_vector, vectors)\n",
        "\n",
        "    best_match_index = np.argmax(similarity_scores)\n",
        "    best_match_score = similarity_scores[0, best_match_index]\n",
        "\n",
        "    # If confidence is low, return a default response\n",
        "    if best_match_score < 0.2:\n",
        "        return \"I'm sorry, I don't understand that. Can you ask something else?\"\n",
        "\n",
        "    return chatbot_corpus[best_match_index]"
      ],
      "metadata": {
        "id": "Int1SYbbooiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main loop\n",
        "def start_chat():\n",
        "    print(\"Chatbot: Hello! Type 'exit' to stop chatting.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        response = chatbot_response(user_input)\n",
        "        print(f\"Chatbot: {response}\")\n",
        "\n",
        "# Start the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRqcD3b_ozr1",
        "outputId": "4a26e714-f164-4b2b-f030-a58d7db9bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! Type 'exit' to stop chatting.\n",
            "You: How can I use AI chatbots?\n",
            "Chatbot: hello how can i help you\n",
            "You: What is Llama 3?\n",
            "Chatbot: llama 3 is a powerful opensource llm\n",
            "You: What is AI?\n",
            "Chatbot: groq is a fast inference engine for ai models\n",
            "You: How does NLP help computers?\n",
            "Chatbot: hello how can i help you\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}